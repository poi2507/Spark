{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession # SparkSession: 스파크 코드를 실행하기 위한 진입점\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\")\\\n",
    "    .option(\"header\",\"true\")\\\n",
    "    .option(\"inferSchema\",\"true\")\\\n",
    "    .load(\"/Users/taewoong/Documents/coding/Spark_practice/data/retail-data/all/*.csv\")\\\n",
    "    .coalesce(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 윈도우 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위도우 함수를 집계에 사용할 수도 있다. 윈도우 함수는 데이터의 특정 'window'를 대상으로 고유의 집계 연산을 수행한다. 데이터의 '위도우'는 현재 데이터에 대한 참조를 사용해 정의 한다. 원도우 명세는 함수에 전달될 로우를 결정한다. 표준 group-by 함수와 유사해보일 수도 있으므로 이 둘의 차이점을 보겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "group-by함수를 사용하면 모든 로우 레크도가 단일 그룹으로만 이동한다. 윈도우 함수는 프레임에 입력되는 모든 로우에 대한 결과값을 계산한다. 프레임은 로우 그룹 기반의 테이블을 의미한다. 각 로우는 하나 이상의 프레임에 할당될 수 있다. 가장 흔하게 사용되는 방법 중 하나는 하루를 나타내는 값의 롤링 평균을 구하는 것이다. 이 작업을 수행하려면 개별 로우가 7개의 다른 프레임으로 구성되어야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "스파크는 다음 세 가지 종류의 윈도우 함수를 지원한다.\n",
    "\n",
    "* 랭크 함수\n",
    "* 분석 함수\n",
    "* 집계 한수\n",
    "\n",
    "\n",
    "![](./IMG_BFA0D4F05227-1.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, to_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfWithDate = df.withColumn(\"date\", to_date(col(\"InvoiceDate\"), \"MM/d/yyyy H:mm\"))\n",
    "dfWithDate.createOrReplaceTempView(\"dfWithDate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "윈도우 함수를 정의하기 위해 첫 번째 단계로 윈도우 명세를 만든다. 여기서 사용하는 partitionBy메서드는 지금까지 사용해온 파티셔닝 스키마의 개념과는 관련이 없으며 그룹을 어떻게 나눌지 결정하는 것과 유사한 개념이다. orderBy 메서드는 파티션의 정렬 방식을 정의한다. 그리고 프레임 명세(rowsBetween 구문)는 입력된 로우의 참조를 기반으로 프레임에 로우가 포함될 수 있는지 경정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowSpec = Window\\\n",
    "  .partitionBy(\"CustomerId\", \"date\")\\\n",
    "  .orderBy(desc(\"Quantity\"))\\\n",
    "  .rowsBetween(Window.unboundedPreceding, Window.currentRow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import max\n",
    "\n",
    "maxPurchaseQuantity = max(col(\"Quantity\")).over(windowSpec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import dense_rank, rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞 예제는 컬럼이나 표현식을 반환하므로 DataFrame의 select 구문에서 사용할 수 있다. dense_rank 함수를 사용해 모든 고객에 대해 최대 구매 수량을 가진 날짜가 언제인지 알아본다. 동일한 값이 나오거나 중복 로우가 발생해 순위가 비어 있을 수 있으며로 rank함수 대산 dense_rank함수를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchaseDenseRank = dense_rank().over(windowSpec)\n",
    "purchaseRank = rank().over(windowSpec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------+------------+-----------------+-------------------+\n",
      "|CustomerId|      date|Quantity|quantityRank|quantityDenseRank|maxPurchaseQuantity|\n",
      "+----------+----------+--------+------------+-----------------+-------------------+\n",
      "|     12346|2011-01-18|   74215|           1|                1|              74215|\n",
      "|     12346|2011-01-18|  -74215|           2|                2|              74215|\n",
      "+----------+----------+--------+------------+-----------------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 레거시 파서를 사용하는 대신 MM / dd / yyyy에서 MM-dd-yyyy\n",
    "spark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\")\n",
    "dfWithDate.where(\"CustomerId IS NOT NULL\").orderBy(\"CustomerId\")\\\n",
    "  .select(\n",
    "    col(\"CustomerId\"),\n",
    "    col(\"date\"),\n",
    "    col(\"Quantity\"),\n",
    "    purchaseRank.alias(\"quantityRank\"),\n",
    "    purchaseDenseRank.alias(\"quantityDenseRank\"),\n",
    "    maxPurchaseQuantity.alias(\"maxPurchaseQuantity\")).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그룹화 셋"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그룹화 셋은 여러 집계를 결합하는 저수준 기증이다. 그룹화 셋을 이용하면 group-by 구문에서 원하는 형태로 집계를 생성할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+----------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|   InvoiceDate|UnitPrice|CustomerID|       Country|      date|\n",
      "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+----------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|12/1/2010 8:26|     2.55|     17850|United Kingdom|2010-12-01|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|12/1/2010 8:26|     3.39|     17850|United Kingdom|2010-12-01|\n",
      "|   536365|   84406B|CREAM CUPID HEART...|       8|12/1/2010 8:26|     2.75|     17850|United Kingdom|2010-12-01|\n",
      "|   536365|   84029G|KNITTED UNION FLA...|       6|12/1/2010 8:26|     3.39|     17850|United Kingdom|2010-12-01|\n",
      "|   536365|   84029E|RED WOOLLY HOTTIE...|       6|12/1/2010 8:26|     3.39|     17850|United Kingdom|2010-12-01|\n",
      "|   536365|    22752|SET 7 BABUSHKA NE...|       2|12/1/2010 8:26|     7.65|     17850|United Kingdom|2010-12-01|\n",
      "|   536365|    21730|GLASS STAR FROSTE...|       6|12/1/2010 8:26|     4.25|     17850|United Kingdom|2010-12-01|\n",
      "|   536366|    22633|HAND WARMER UNION...|       6|12/1/2010 8:28|     1.85|     17850|United Kingdom|2010-12-01|\n",
      "|   536366|    22632|HAND WARMER RED P...|       6|12/1/2010 8:28|     1.85|     17850|United Kingdom|2010-12-01|\n",
      "|   536367|    84879|ASSORTED COLOUR B...|      32|12/1/2010 8:34|     1.69|     13047|United Kingdom|2010-12-01|\n",
      "|   536367|    22745|POPPY'S PLAYHOUSE...|       6|12/1/2010 8:34|      2.1|     13047|United Kingdom|2010-12-01|\n",
      "|   536367|    22748|POPPY'S PLAYHOUSE...|       6|12/1/2010 8:34|      2.1|     13047|United Kingdom|2010-12-01|\n",
      "|   536367|    22749|FELTCRAFT PRINCES...|       8|12/1/2010 8:34|     3.75|     13047|United Kingdom|2010-12-01|\n",
      "|   536367|    22310|IVORY KNITTED MUG...|       6|12/1/2010 8:34|     1.65|     13047|United Kingdom|2010-12-01|\n",
      "|   536367|    84969|BOX OF 6 ASSORTED...|       6|12/1/2010 8:34|     4.25|     13047|United Kingdom|2010-12-01|\n",
      "|   536367|    22623|BOX OF VINTAGE JI...|       3|12/1/2010 8:34|     4.95|     13047|United Kingdom|2010-12-01|\n",
      "|   536367|    22622|BOX OF VINTAGE AL...|       2|12/1/2010 8:34|     9.95|     13047|United Kingdom|2010-12-01|\n",
      "|   536367|    21754|HOME BUILDING BLO...|       3|12/1/2010 8:34|     5.95|     13047|United Kingdom|2010-12-01|\n",
      "|   536367|    21755|LOVE BUILDING BLO...|       3|12/1/2010 8:34|     5.95|     13047|United Kingdom|2010-12-01|\n",
      "|   536367|    21777|RECIPE BOX WITH M...|       4|12/1/2010 8:34|     7.95|     13047|United Kingdom|2010-12-01|\n",
      "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfNoNull = dfWithDate.drop()\n",
    "dfNoNull.createOrReplaceTempView(\"dfNoNull\")\n",
    "dfNoNull.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 롤업"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금까지는 명시적 그룹화를 알아보았다. 다양한 컬럼을 그룹화 키로 설정하면 그룹화 키로 설정된 조합뿐만 아니라 데이터셋이세 볼 수 있는 실제 조합을 모두 살펴볼수 있다 롤업은 group-by 스타일의 다양한 연산을 수행할 수 있는 다차원 집계 기능이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+--------------+\n",
      "|      Date|       Country|total_quantity|\n",
      "+----------+--------------+--------------+\n",
      "|      null|          null|       5176450|\n",
      "|2010-12-01|   Netherlands|            97|\n",
      "|2010-12-01|     Australia|           107|\n",
      "|2010-12-01|          null|         26814|\n",
      "|2010-12-01|        France|           449|\n",
      "|2010-12-01|          EIRE|           243|\n",
      "|2010-12-01|       Germany|           117|\n",
      "|2010-12-01|        Norway|          1852|\n",
      "|2010-12-01|United Kingdom|         23949|\n",
      "|2010-12-02|          EIRE|             4|\n",
      "|2010-12-02|       Germany|           146|\n",
      "|2010-12-02|          null|         21023|\n",
      "|2010-12-02|United Kingdom|         20873|\n",
      "|2010-12-03|        Poland|           140|\n",
      "|2010-12-03|       Belgium|           528|\n",
      "|2010-12-03|       Germany|           170|\n",
      "|2010-12-03|         Spain|           400|\n",
      "|2010-12-03|         Italy|           164|\n",
      "|2010-12-03|      Portugal|            65|\n",
      "|2010-12-03|          null|         14830|\n",
      "+----------+--------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rolledUpDF = dfNoNull.rollup(\"Date\", \"Country\").agg(sum(col(\"Quantity\")))\\\n",
    "  .selectExpr(\"Date\", \"Country\", \"`sum(Quantity)` as total_quantity\")\\\n",
    "  .orderBy(\"Date\")\n",
    "rolledUpDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 큐브\n",
    "\n",
    "큐브는 롤업을 고차원적으로 사용할 수 있게 해준다. 큐브는 요소들을 계층적으로 다루는 대신 모든 차원에 대해 동일한 작업을 수행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+-------------+\n",
      "|Date|             Country|sum(Quantity)|\n",
      "+----+--------------------+-------------+\n",
      "|null|           Australia|        83653|\n",
      "|null|               Japan|        25218|\n",
      "|null|               Italy|         7999|\n",
      "|null|                 USA|         1034|\n",
      "|null|             Germany|       117448|\n",
      "|null|         Unspecified|         3300|\n",
      "|null|                null|      5176450|\n",
      "|null|             Lebanon|          386|\n",
      "|null|           Hong Kong|         4769|\n",
      "|null|                 RSA|          352|\n",
      "|null|           Singapore|         5234|\n",
      "|null|     Channel Islands|         9479|\n",
      "|null|               Spain|        26824|\n",
      "|null|             Finland|        10666|\n",
      "|null|  European Community|          497|\n",
      "|null|             Denmark|         8188|\n",
      "|null|              Cyprus|         6317|\n",
      "|null|      Czech Republic|          592|\n",
      "|null|United Arab Emirates|          982|\n",
      "|null|              Norway|        19247|\n",
      "+----+--------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum\n",
    "\n",
    "dfNoNull.cube(\"Date\", \"Country\").agg(sum(col(\"Quantity\")))\\\n",
    "  .select(\"Date\", \"Country\", \"sum(Quantity)\").orderBy(\"Date\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그룹화 메타 데이터\n",
    "\n",
    "큐브와 롤업을 사용하다 보면 집계 수준에 따라 쉽게 필터링하기 위해 집계 수준을 조회하는 경우가 발생한다. 이때 grouping_id를 사용한다. grouping_id는 결과 데이터섹의 집계 수준을 명시하는 컬럼을 제공한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 피벗\n",
    "\n",
    "피벗을 사용해 로우를 컬럼으러 변환할 수 있다. 현재 데이터셋에는 Country 컬럼이 있다 피벗을 사용해 국가별로 집계 함수를 적용할 수 있으며 쿼리슷 사용해 쉽게 결과를 확인할 수 있다,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted = dfWithDate.groupBy(\"date\").pivot(\"Country\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted.where(\"date > '2011-12-05'\").select(\"date\",\"'Norway_sum(Quantity)'\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
